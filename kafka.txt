 docker exec -it kafka1 env | Select-String "KAFKA"
docker-compose down --volumes --remove-orphans

ping 192.168.117.128

source myenv/bin/activate

تشغيل الاسكيما 
./confluent-7.5.0/bin/schema-registry-start ./schema-registry.properties



------------------------
kcat-b  192.168.117.128:9094 -C -t chat_messages -o end


Swagger UI: http://localhost:8000/swagger/
ReDoc: http://localhost:8000/redoc/
JSON Schema: http://localhost:8000/swagger.json


docker-compose down --remove-orphans

مراقبه المواضيع
docker exec -it kafka1 kafka-topics --describe --topic my-topic --bootstrap-server kafka1:9093


127.0.0.1:6379
kafka-storage.bat format -t 3fbd47a9-4329-4d6e-b0f9-0538b23f91f6 -c ..\..\config\server.properties --initial-controllers

-------------------------------------------------------------------------------------------------------------------
wsl -d Ubuntu
172.26.176.1

 ~/kafka_2.13-3.0.0/bin/kafka-server-start.sh ~/kafka_2.13-3.0.0/config/kraft/server.properties



kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic first_topic


 تنتج رسالة في موضوع كافكا باستخدام CLI

kafka-console-producer.sh --bootstrap-server localhost:9092 --topic first_topic
--------------------------------------------------------------------------
services:
  zookeeper:
    image: wurstmeister/zookeeper
    volumes:
      - ./data:/data
    ports:
      - "12181:2181"

  kafka:
    image: wurstmeister/kafka
    ports:
      - "19092:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: localhost
      KAFKA_MESSAGE_MAX_BYTES: 2000000
      KAFKA_CREATE_TOPICS: "Topic1:1:3,Topic2:1:1:compact"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - ./kafka-logs:/kafka
      - /var/run/docker.sock:/var/run/docker.sock

  kafka-manager:
    image: sheepkiller/kafka-manager
    network_mode: host
    environment:
      ZK_HOSTS: localhost:12181
      APPLICATION_SECRET: random-secret











-------------------------------------------------------------------------------------------------------------
services:
  kafka1:
    image: confluentinc/cp-kafka:latest
    container_name: kafka1
    restart: always
    ports:
      - "9094:9094"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://kafka1:29092,CONTROLLER://kafka1:29093,PLAINTEXT_HOST://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:29092,PLAINTEXT_HOST://192.168.117.128:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka1:29093'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      # Settings to prevent duplicate messages
      KAFKA_ENABLE_IDEMPOTENCE: 'true'
      KAFKA_MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION: 5
      KAFKA_ACKS: 'all'
      KAFKA_RETRIES: 2147483647
      KAFKA_REQUEST_TIMEOUT_MS: 300000
      KAFKA_DELIVERY_TIMEOUT_MS: 600000
    volumes:
      - ./kafka1-data:/tmp/kraft-combined-logs

  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    container_name: kafdrop
    restart: always
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "kafka1:29092"
      JVM_OPTS: "-Xms64M -Xmx128M"  # Increased memory
      SERVER_SERVLET_CONTEXTPATH: "/"
      KAFKA_PROPERTIES: "fetch.message.max.bytes=50000000"
      CMD_ARGS: "--message.format=DEFAULT"
    depends_on:
      - kafka1

networks:
  default:
    driver: bridge
